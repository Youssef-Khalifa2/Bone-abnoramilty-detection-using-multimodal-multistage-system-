{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:40:31.588802Z","iopub.status.busy":"2024-04-28T18:40:31.588428Z","iopub.status.idle":"2024-04-28T18:41:02.010746Z","shell.execute_reply":"2024-04-28T18:41:02.009820Z","shell.execute_reply.started":"2024-04-28T18:40:31.588769Z"},"trusted":true,"id":"OsaEo9ip-gd1"},"outputs":[],"source":["!pip install git+https://github.com/qubvel/classification_models.git\n","from classification_models.tfkeras import Classifiers\n","from PIL import Image\n","import os\n","import tensorflow as tf\n","import pandas as pd\n","import keras\n","from keras import layers, regularizers\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.applications.densenet import DenseNet169, preprocess_input\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T18:41:02.014228Z","iopub.status.busy":"2024-04-28T18:41:02.013074Z"},"trusted":true,"id":"H3oUuTuu-gd2"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime\n","counter = 0\n","\n","def roi_clahe_pre_process(path, output_directory):\n","    global counter  # Access the global counter variable\n","\n","    img = cv2.imread(path)\n","\n","    # Convert image to grayscale\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply thresholding\n","    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n","\n","    # Determine bounding rectangle of the thresholded image\n","    x, y, w, h = cv2.boundingRect(thresh)\n","    x, y, w, h = x, y, w + 20, h + 20\n","\n","    # Crop the original image based on the bounding rectangle\n","    img = img[y:y+h, x:x+w]\n","\n","    # Convert the cropped image to grayscale\n","    gray_crop = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply CLAHE\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","    clahe_img = clahe.apply(gray_crop)\n","\n","    # Construct the output file path\n","    filename = os.path.basename(path)\n","    output_filename = filename[:-4] + '__enhanced_' + str(counter) + filename[-4:]\n","    output_path = os.path.join(output_directory, output_filename)\n","\n","    # Save the output image\n","    cv2.imwrite(output_path, clahe_img)\n","    print(f\"Image saved to {output_path}\")\n","\n","    # Increment the counter\n","    counter += 1\n","\n","    return output_path\n","\n","\n","prefix = '/kaggle/input/better-mura/MURA-v1.1/'\n","output_directory = '/kaggle/working'\n","excel_file_path = '/kaggle/input/better-mura/MURA-v1.1/MURA-v1.1/train_augmented.csv'\n","df = pd.read_csv(excel_file_path)\n","df = df[df[\"path\"].str.contains(r\"XR_SHOULDER\")]\n","paths = prefix + df['path'].astype(str)\n","labels = df['label']\n","labels = pd.Series(labels, name='Label')\n","labels = labels.astype(str)\n","t_images = pd.concat([paths, labels], axis=1)\n","print(t_images)\n","for index, row in t_images.iterrows():\n","    image_path = row[\"path\"]\n","    label = row[\"Label\"]\n","    enhanced = roi_clahe_pre_process(image_path , output_directory)\n","    #output_path=stat_range(image_path)\n","    # Create a DataFrame with the original and equalized image paths\n","    df_output = pd.DataFrame({'Original Path': [image_path], 'Enhanced Path': [enhanced], 'Label': [label]})\n","        # Append the DataFrame to the output CSV file\n","    if not os.path.isfile('/kaggle/working/Enhanced_Labeled.csv'):\n","            df_output.to_csv('/kaggle/working/Enhanced_Labeled.csv', index=False)\n","    else:\n","            df_output.to_csv('/kaggle/working/Enhanced_Labeled.csv', mode='a', header=False, index=False)\n","print(\"===============Done with training images===================\")\n","valid_data = pd.read_csv('/kaggle/input/better-mura/MURA-v1.1/MURA-v1.1/valid.csv')\n","valid_data = valid_data[valid_data[\"BodyPart\"].str.contains(r\"XR_SHOULDER\")]\n","paths = prefix + valid_data['path'].astype(str)\n","labels = valid_data['label']\n","labels = pd.Series(labels, name='Label')\n","labels = labels.astype(str)\n","v_images = pd.concat([paths, labels], axis=1)\n","print(v_images)\n","for index, row in v_images.iterrows():\n","    image_path = row[\"path\"]\n","    label = row[\"Label\"]\n","    enhanced = roi_clahe_pre_process(image_path , output_directory)\n","    #output_path=stat_range(image_path)\n","    # Create a DataFrame with the original and equalized image paths\n","    df_output = pd.DataFrame({'Original Path': [image_path], 'Enhanced Path': [enhanced], 'Label': [label]})\n","        # Append the DataFrame to the output CSV file\n","    if not os.path.isfile('/kaggle/working/Valid_Enhanced_Labeled.csv'):\n","            df_output.to_csv('/kaggle/working/Valid_Enhanced_Labeled.csv', index=False)\n","    else:\n","            df_output.to_csv('/kaggle/working/Valid_Enhanced_Labeled.csv', mode='a', header=False, index=False)\n","print(\"===============Done with test images===================\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"Z_NnvlHB-gd3"},"outputs":[],"source":["class_num=1\n","batch_size = 32\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","# 1. Load the images and labels\n","\n","#training Data Loading\n","prefix = '/kaggle/input/better-mura/MURA-v1.1/'\n","train_data = pd.read_csv('/kaggle/working/Enhanced_Labeled.csv')\n","\n","\n","paths = train_data['Enhanced Path'].astype(str)\n","labels = train_data['Label']\n","labels = pd.Series(labels, name='Label')\n","labels = labels.astype(str)\n","t_images = pd.concat([paths, labels], axis=1)\n","print(t_images)\n","train_df, test_df = train_test_split(t_images, train_size=0.8, shuffle=True, random_state=1)\n","#testing Data Loading\n","valid_data = pd.read_csv('/kaggle/working/Valid_Enhanced_Labeled.csv')\n","paths = valid_data['Enhanced Path'].astype(str)\n","labels = valid_data['Label']\n","labels = pd.Series(labels, name='Label')\n","labels = labels.astype(str)\n","v_images = pd.concat([paths, labels], axis=1)\n","print(v_images)\n","# 2. Augmentation\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Define augmentation parameters\n","datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"z8XwGS4Z-gd4"},"outputs":[],"source":["#creating batch loaders to size :\n","imgsize = 224\n","xcol = \"Enhanced Path\"\n","Train_image_generator = datagen.flow_from_dataframe(\n","    dataframe=train_df,\n","    directory=None,  # Directory is None because we're providing full paths in image_paths\n","    x_col = xcol,\n","    y_col=\"Label\",\n","    target_size=(imgsize,imgsize),  # Specify your image dimensions\n","    batch_size=batch_size,\n","    class_mode=\"binary\"  # Assuming binary classification, change if needed\n",")\n","\n","Test_image_generator = datagen.flow_from_dataframe(\n","    dataframe=test_df,\n","    directory=None,  # Directory is None because we're providing full paths in image_paths\n","    x_col = xcol,\n","    y_col=\"Label\",\n","    target_size=(imgsize,imgsize),  # Specify your image dimensions\n","    batch_size=batch_size,\n","    class_mode=\"binary\"  # Assuming binary classification, change if needed\n",")\n","valid_generator = datagen.flow_from_dataframe(\n","    dataframe=v_images, directory=None,\n","    x_col = xcol,\n","    y_col=\"Label\",\n","    target_size=(imgsize,imgsize),\n","    class_mode=\"binary\",\n","    batch_size=batch_size,\n","    shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"BTU_6wJ8-gd4"},"outputs":[],"source":["from keras.models import Model\n","from keras.layers import Input, Flatten, BatchNormalization, Dense, Activation, Dropout\n","from keras.applications import Xception\n","from keras.models import load_model\n","import shutil\n","\n","# Source path of the model\n","source_path = \"/kaggle/input/xception-shoulder/keras/xception-shoulder/3/MobilenetV2_shoulder.keras\"\n","# Destination path where you can write\n","destination_path = \"/kaggle/working/model.keras\"\n","\n","# Copy the model file\n","shutil.copyfile(source_path, destination_path)\n","\n","# Now load the model from the copied file\n","model = load_model(destination_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"trusted":true,"id":"OdxSvP1o-gd4"},"outputs":[],"source":["X_val = []\n","y_val = []\n","\n","for index, row in v_images.iterrows():\n","    image_path = row[\"Enhanced Path\"]\n","    label = row[\"Label\"]\n","\n","    # Load and preprocess the image\n","    image = Image.open(image_path).resize((imgsize, imgsize)).convert('RGB')\n","    image = np.array(image) / 255.0\n","\n","    # Append the preprocessed image and label to X_val and y_val lists\n","    X_val.append(image)\n","    y_val.append(label)\n","\n","# Convert lists to numpy arrays\n","X_val = np.array(X_val)\n","y_val = np.array(y_val)\n","y_val = y_val.astype(int)\n","# Evaluate the model on the entire validation dataset\n","loss, accuracy = model.evaluate(X_val, y_val)\n","print(f\"Loss: {loss}\")\n","print(f\"Accuracy: {accuracy}\")\n"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-04-01T16:07:28.158527Z","iopub.status.busy":"2024-04-01T16:07:28.157657Z","iopub.status.idle":"2024-04-01T16:07:43.880889Z","shell.execute_reply":"2024-04-01T16:07:43.880084Z","shell.execute_reply.started":"2024-04-01T16:07:28.158492Z"},"id":"mLNgod4s-gd5"},"source":["from keras.models import load_model\n","model_1 = load_model('/kaggle/working/enhanced_densenet_169_shoulder.keras')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4358814,"sourceId":7921122,"sourceType":"datasetVersion"},{"datasetId":4710352,"sourceId":7999249,"sourceType":"datasetVersion"},{"modelInstanceId":20980,"sourceId":24898,"sourceType":"modelInstanceVersion"},{"isSourceIdPinned":true,"modelInstanceId":34776,"sourceId":41721,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}