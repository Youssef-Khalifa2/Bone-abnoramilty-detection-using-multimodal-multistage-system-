{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T16:51:49.406521Z","iopub.status.busy":"2024-04-28T16:51:49.40617Z","iopub.status.idle":"2024-04-28T16:52:19.101854Z","shell.execute_reply":"2024-04-28T16:52:19.100956Z","shell.execute_reply.started":"2024-04-28T16:51:49.40649Z"},"trusted":true,"id":"o24mjyfO-g7X"},"outputs":[],"source":["!pip install git+https://github.com/qubvel/classification_models.git\n","from classification_models.tfkeras import Classifiers\n","from PIL import Image\n","import os\n","import tensorflow as tf\n","import pandas as pd\n","import keras\n","from keras import layers, regularizers\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.applications.densenet import DenseNet169, preprocess_input\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T16:52:19.104106Z","iopub.status.busy":"2024-04-28T16:52:19.103566Z","iopub.status.idle":"2024-04-28T17:08:01.560228Z","shell.execute_reply":"2024-04-28T17:08:01.559285Z","shell.execute_reply.started":"2024-04-28T16:52:19.104079Z"},"trusted":true,"id":"xTSoT6E_-g7Y"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime\n","counter = 0\n","\n","def roi_clahe_pre_process(path, output_directory):\n","    global counter  # Access the global counter variable\n","\n","    img = cv2.imread(path)\n","\n","    # Convert image to grayscale\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply thresholding\n","    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n","\n","    # Determine bounding rectangle of the thresholded image\n","    x, y, w, h = cv2.boundingRect(thresh)\n","    x, y, w, h = x, y, w + 20, h + 20\n","\n","    # Crop the original image based on the bounding rectangle\n","    img = img[y:y+h, x:x+w]\n","\n","    # Convert the cropped image to grayscale\n","    gray_crop = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # Apply CLAHE\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n","    clahe_img = clahe.apply(gray_crop)\n","\n","    # Construct the output file path\n","    filename = os.path.basename(path)\n","    output_filename = filename[:-4] + '__enhanced_' + str(counter) + filename[-4:]\n","    output_path = os.path.join(output_directory, output_filename)\n","\n","    # Save the output image\n","    cv2.imwrite(output_path, clahe_img)\n","    print(f\"Image saved to {output_path}\")\n","\n","    # Increment the counter\n","    counter += 1\n","\n","    return output_path\n","\n","\n","prefix = '/kaggle/input/better-mura/MURA-v1.1/'\n","output_directory = '/kaggle/working'\n","excel_file_path = '/kaggle/input/better-mura/MURA-v1.1/MURA-v1.1/train_augmented.csv'\n","df = pd.read_csv(excel_file_path)\n","df = df[df[\"path\"].str.contains(r\"XR_SHOULDER\")]\n","paths = prefix + df['path'].astype(str)\n","labels = df['label']\n","labels = pd.Series(labels, name='Label')\n","labels = labels.astype(str)\n","t_images = pd.concat([paths, labels], axis=1)\n","print(t_images)\n","for index, row in t_images.iterrows():\n","    image_path = row[\"path\"]\n","    label = row[\"Label\"]\n","    enhanced = roi_clahe_pre_process(image_path , output_directory)\n","    #output_path=stat_range(image_path)\n","    # Create a DataFrame with the original and equalized image paths\n","    df_output = pd.DataFrame({'Original Path': [image_path], 'Enhanced Path': [enhanced], 'Label': [label]})\n","        # Append the DataFrame to the output CSV file\n","    if not os.path.isfile('/kaggle/working/Enhanced_Labeled.csv'):\n","            df_output.to_csv('/kaggle/working/Enhanced_Labeled.csv', index=False)\n","    else:\n","            df_output.to_csv('/kaggle/working/Enhanced_Labeled.csv', mode='a', header=False, index=False)\n","print(\"===============Done with training images===================\")\n","valid_data = pd.read_csv('/kaggle/input/better-mura/MURA-v1.1/MURA-v1.1/valid.csv')\n","valid_data = valid_data[valid_data[\"BodyPart\"].str.contains(r\"XR_SHOULDER\")]\n","paths = prefix + valid_data['path'].astype(str)\n","labels = valid_data['label']\n","labels = pd.Series(labels, name='Label')\n","labels = labels.astype(str)\n","v_images = pd.concat([paths, labels], axis=1)\n","print(v_images)\n","for index, row in v_images.iterrows():\n","    image_path = row[\"path\"]\n","    label = row[\"Label\"]\n","    enhanced = roi_clahe_pre_process(image_path , output_directory)\n","    #output_path=stat_range(image_path)\n","    # Create a DataFrame with the original and equalized image paths\n","    df_output = pd.DataFrame({'Original Path': [image_path], 'Enhanced Path': [enhanced], 'Label': [label]})\n","        # Append the DataFrame to the output CSV file\n","    if not os.path.isfile('/kaggle/working/Valid_Enhanced_Labeled.csv'):\n","            df_output.to_csv('/kaggle/working/Valid_Enhanced_Labeled.csv', index=False)\n","    else:\n","            df_output.to_csv('/kaggle/working/Valid_Enhanced_Labeled.csv', mode='a', header=False, index=False)\n","print(\"===============Done with test images===================\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T17:08:01.562214Z","iopub.status.busy":"2024-04-28T17:08:01.561406Z","iopub.status.idle":"2024-04-28T17:08:01.755035Z","shell.execute_reply":"2024-04-28T17:08:01.754098Z","shell.execute_reply.started":"2024-04-28T17:08:01.562178Z"},"trusted":true,"id":"5IgX1-U8-g7Y"},"outputs":[],"source":["class_num=1\n","batch_size = 32\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","# 1. Load the images and labels\n","\n","#training Data Loading\n","prefix = '/kaggle/input/better-mura/MURA-v1.1/'\n","#train_data = pd.read_csv('/kaggle/input/better-mura/MURA-v1.1/MURA-v1.1/train_augmented.csv')\n","train_data = pd.read_csv('/kaggle/working/Enhanced_Labeled.csv')\n","\n","#train_data = train_data[train_data[\"BodyPart\"].str.contains(r\"XR_SHOULDER\")]\n","paths = train_data['Enhanced Path'].astype(str)\n","#paths = prefix + train_data['path']\n","labels = train_data['Label']\n","labels = pd.Series(labels, name='Label')\n","labels = labels.astype(str)\n","t_images = pd.concat([paths, labels], axis=1)\n","print(t_images)\n","train_df, test_df = train_test_split(t_images, train_size=0.8, shuffle=True, random_state=1)\n","#testing Data Loading\n","#valid_data = pd.read_csv('/kaggle/input/better-mura/MURA-v1.1/MURA-v1.1/valid.csv')\n","valid_data = pd.read_csv('/kaggle/working/Valid_Enhanced_Labeled.csv')\n","#valid_data = valid_data[valid_data[\"BodyPart\"].str.contains(r\"XR_SHOULDER\")]\n","paths = valid_data['Enhanced Path'].astype(str)\n","#paths = prefix + valid_data['path']\n","labels = valid_data['Label']\n","labels = pd.Series(labels, name='Label')\n","labels = labels.astype(str)\n","v_images = pd.concat([paths, labels], axis=1)\n","print(v_images)\n","# 2. Augmentation\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Define augmentation parameters\n","datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T17:08:01.758434Z","iopub.status.busy":"2024-04-28T17:08:01.757833Z","iopub.status.idle":"2024-04-28T17:08:02.350346Z","shell.execute_reply":"2024-04-28T17:08:02.349527Z","shell.execute_reply.started":"2024-04-28T17:08:01.758402Z"},"trusted":true,"id":"njUESkSK-g7Y"},"outputs":[],"source":["#creating batch loaders to size :\n","imgsize = 224\n","xcol = \"Enhanced Path\"\n","Train_image_generator = datagen.flow_from_dataframe(\n","    dataframe=train_df,\n","    directory=None,  # Directory is None because we're providing full paths in image_paths\n","    x_col = xcol,\n","    y_col=\"Label\",\n","    target_size=(imgsize,imgsize),  # Specify your image dimensions\n","    batch_size=batch_size,\n","    class_mode=\"binary\"  # Assuming binary classification, change if needed\n",")\n","\n","Test_image_generator = datagen.flow_from_dataframe(\n","    dataframe=test_df,\n","    directory=None,  # Directory is None because we're providing full paths in image_paths\n","    x_col = xcol,\n","    y_col=\"Label\",\n","    target_size=(imgsize,imgsize),  # Specify your image dimensions\n","    batch_size=batch_size,\n","    class_mode=\"binary\"  # Assuming binary classification, change if needed\n",")\n","valid_generator = datagen.flow_from_dataframe(\n","    dataframe=v_images, directory=None,\n","    x_col = xcol,\n","    y_col=\"Label\",\n","    target_size=(imgsize,imgsize),\n","    class_mode=\"binary\",\n","    batch_size=batch_size,\n","    shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T17:08:02.351674Z","iopub.status.busy":"2024-04-28T17:08:02.351401Z","iopub.status.idle":"2024-04-28T17:08:04.774558Z","shell.execute_reply":"2024-04-28T17:08:04.773742Z","shell.execute_reply.started":"2024-04-28T17:08:02.351649Z"},"trusted":true,"id":"i63ePVsz-g7Z"},"outputs":[],"source":["from keras.models import Model\n","from keras.layers import Input, Flatten, BatchNormalization, Dense, Activation, Dropout\n","from keras.applications import MobileNetV2\n","from keras.models import load_model\n","import shutil\n","import tensorflow as tf\n","\n","# Base Xception model\n","base_Neural_Net= tf.keras.applications.MobileNetV2(input_shape=(224,224,3), weights='imagenet', include_top=False)\n","\n","# Freeze the weights of the base model\n","base_Neural_Net.trainable = True\n","\n","# Define the input layer\n","inputs = tf.keras.Input(shape=(224, 224, 3))\n","\n","# Connect the input with the base model\n","x = base_Neural_Net(inputs)\n","\n","# Flatten layer\n","x = tf.keras.layers.Flatten()(x)\n","\n","# Batch Normalization layer\n","x = tf.keras.layers.BatchNormalization()(x)\n","\n","# Dense layer with 256 units\n","x = tf.keras.layers.Dense(256, kernel_initializer='he_uniform')(x)\n","\n","# Batch Normalization layer\n","x = tf.keras.layers.BatchNormalization()(x)\n","\n","# ReLU activation\n","x = tf.keras.layers.Activation('relu')(x)\n","\n","# Dropout layer\n","x = tf.keras.layers.Dropout(0.5)(x)\n","\n","# Output layer\n","outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","\n","# Create the model\n","model = tf.keras.Model(inputs, outputs)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-28T17:08:04.77642Z","iopub.status.busy":"2024-04-28T17:08:04.775792Z"},"trusted":true,"id":"B2NwZRo1-g7Z"},"outputs":[],"source":["import keras.callbacks\n","checkpoint_path = '/kaggle/working/Xception_shoulder-v2.keras'\n","Monitored_metric='val_loss'\n","# Create an EarlyStopping callback\n","early_stopping = EarlyStopping(monitor=Monitored_metric,  # The metric to monitor for early stopping\n","                               patience=6,  # Number of epochs with no improvement after which training will be stopped\n","                               verbose=1,  # Verbosity level\n","                               restore_best_weights=True)  # Restore model weights from the epoch with the best value of the monitored metric\n","\n","# Create a ModelCheckpoint callback\n","model_checkpoint = ModelCheckpoint(checkpoint_path,\n","                                   monitor=Monitored_metric,  # The metric to monitor for saving the best model\n","                                   save_best_only=True,  # Save only the best model\n","                                   mode='min',  # Mode for the 'monitor' metric (e.g., 'min' for loss)\n","                                   verbose=1)  # Verbosity level\n","learn_control = tf.keras.callbacks.ReduceLROnPlateau(monitor=Monitored_metric,\n","                                  patience=2,\n","                                  verbose=1,\n","                                  factor=0.2,\n","                                  min_lr=1e-7)\n","batch_size = 32\n","history = model.fit(Train_image_generator,\n","                    epochs=50,\n","                    batch_size=batch_size,\n","                    steps_per_epoch=len(t_images) // batch_size,\n","                    validation_data=Test_image_generator,\n","                    callbacks=[early_stopping,model_checkpoint,learn_control],\n","                    verbose = 2)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"a8ArlGcH-g7Z"},"outputs":[],"source":["history_df = pd.DataFrame(history.history)\n","history_df[['loss', 'val_loss']].plot()"]},{"cell_type":"code","source":["# Loading the saved model\n","from keras.models import Model\n","from keras.layers import Input, Flatten, BatchNormalization, Dense, Activation, Dropout\n","from keras.applications import Xception\n","from keras.models import load_model\n","import shutil\n","\n","# Source path of the model\n","source_path = \"/kaggle/input/xception-shoulder/keras/xception-shoulder/3/MobilenetV2_shoulder.keras\"\n","# Destination path where you can write\n","destination_path = \"/kaggle/working/model.keras\"\n","\n","# Copy the model file\n","shutil.copyfile(source_path, destination_path)\n","\n","# Now load the model from the copied file\n","model = load_model(destination_path)"],"metadata":{"id":"TIe3g0A4BbnO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#testing the loaded model\n","X_val = []\n","y_val = []\n","\n","for index, row in v_images.iterrows():\n","    image_path = row[\"Enhanced Path\"]\n","    label = row[\"Label\"]\n","\n","    # Load and preprocess the image\n","    image = Image.open(image_path).resize((imgsize, imgsize)).convert('RGB')\n","    image = np.array(image) / 255.0\n","\n","    # Append the preprocessed image and label to X_val and y_val lists\n","    X_val.append(image)\n","    y_val.append(label)\n","\n","# Convert lists to numpy arrays\n","X_val = np.array(X_val)\n","y_val = np.array(y_val)\n","y_val = y_val.astype(int)\n","# Evaluate the model on the entire validation dataset\n","loss, accuracy = model.evaluate(X_val, y_val)\n","print(f\"Loss: {loss}\")\n","print(f\"Accuracy: {accuracy}\")"],"metadata":{"id":"HzXdwBhpDmca"},"execution_count":null,"outputs":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4358814,"sourceId":7921122,"sourceType":"datasetVersion"},{"datasetId":4710352,"sourceId":7999249,"sourceType":"datasetVersion"},{"modelInstanceId":20980,"sourceId":24898,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}